
# GTMind â€” Autonomous Research Agent ğŸ”

> **From a single query to a structured, sourceâ€‘linked research report.**  
> Searches the web â†’ cleans articles â†’ extracts insights with GPTâ€‘4o â†’ deâ€‘duplicates & ranks â†’ serves JSON, SQLite, CLI, and a Streamlit UI.

---

## âœ¨ Whatâ€™s inside?

| Layer | Module | Tech / Libs | Purpose |
|-------|--------|-------------|---------|
| **Search**      | `core/search.py`      | Serper.dev Â· `httpx`          | Googleâ€‘style search â†’ URLs |
| **Parse**       | `core/parse.py`       | Async `httpx` Â· `trafilatura` | Download & boilerplateâ€‘strip HTML |
| **Extract**     | `core/extract.py`     | OpenAI GPTâ€‘4o Â· functionâ€‘calling | Pull trends, companies, gaps |
| **Aggregate**   | `core/aggregate.py`   | RapidFuzz Â· frequency rank    | Deâ€‘dupe & merge into a report |
| **Persist**     | `persistence.py`      | SQLite Â· `sqlmodel`           | `--save-sqlite` for history |
| **Serve**       | `api/run.py`          | FastAPI Â· Typer CLI           | `/report` JSON Â· `gtmind` CLI cmd |
| **UI**          | `ui/app.py`           | Streamlit                     | Query box, saved list, twoâ€‘column companies |

---

## ğŸ–¼ Architecture

```mermaid
flowchart LR
    Q(Query) --> S(Search Service)
    S --> P[Downloader + Trafilatura]
    P --> E[OpenAI Extractor]
    E --> A[Aggregator]
    A --> J[ResearchReport JSON]
    J -->|CLI| C[Typer]
    J -->|SQLite| D[(DB)]
    J -->|HTTP| F[FastAPI]
    J -->|UI| U[Streamlit]
```

---

## ğŸ“‹ Requirements

- Python 3.10+
- OpenAI API key
- Serper.dev API key (for Google-style search)
- Poetry (for dependency management)

---

## ğŸš€ QuickÂ Start


### Installation and Setup

Clone the repository and install dependencies:

```bash
git clone https://github.com/amritkochar/GTMind.git && cd GTMind
make install  # poetry deps + tools
```

#### Set Up Environment Variables

Before running the application, ensure you have a `.env` file in the root directory. You can create one by copying the provided `.env.example` file:

```bash
cp .env.example .env
```

Then, open the `.env` file and add your API keys:

```bash
OPENAI_API_KEY="sk-â€¢â€¢â€¢"
SEARCH_API_KEY="serp_â€¢â€¢â€¢"
```

These keys are required for the application to function properly. Please do not commit these keys to Github.

#### Start the Application

Run the following commands to start the backend and frontend services:

```bash
make serve  # FastAPI on :8000
make ui     # Streamlit on :8501
```

### CLI Example

```bash
poetry run gtmind run "AI in biotechnology" \
    --out biotech.json \
    --save-sqlite my.db
```

### API Example

```
GET http://localhost:8000/report?q=AI+in+retail
```

### UI Example

```
streamlit run src/gtmind/ui/app.py
```

* ğŸ”¹ Twoâ€‘column company list  
* ğŸŸ¢ Greenâ€‘highlighted whitespace gaps  
* ğŸ“š Sidebar of mostâ€‘recent reports (reads SQLite)

---

## ğŸ“‚ Project Layout

```
src/gtmind/
â”œâ”€ core/                # search, parse, extract, aggregate
â”œâ”€ api/                 # FastAPI + Typer CLI
â”œâ”€ ui/                  # Streamlit frontâ€‘end
â”œâ”€ persistence.py       # SQLite helpers
â”œâ”€ sample_outputs/      # example JSON reports
â””â”€ tests/               # unit + integration
```

---

## ğŸ“‚ Sample Outputs

Real JSON examples live in [`sample_outputs/`](sample_outputs):

* `ai_in_retail.json`
* `ai_in_healthcare.json`

---

## ğŸ›£ Future Roadmap

* ğŸ” Vector cache of article embeddings for faster reâ€‘runs  
* âœ¨ RAG enrichment for deeper summaries 
* ğŸŒ OAuthâ€‘guarded web UI & shareable URLs
* ğŸ¤– Scheduled cron search with email digests
* ğŸ³ Docker container & CI pipeline

---

## ğŸ¤ Contributing

```bash
make check   # lint (ruff) + typeâ€‘check (mypy)
make test    # run pytest
```

Pull requests welcome â€” please keep tests green! ğŸ‰

---
